{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proteome Data Commons (PDC) Clustergram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "*Please note: This notebook uses open access data*\n",
    "\n",
    "\n",
    "If you are viewing the HTML, the notebook can be found [here.](https://github.com/esacinc/PDC-Public/blob/master/API_documentation/PDC_clustergram.ipynb)\n",
    "\n",
    "This notebook attempts to demonstrate the following:\n",
    "\n",
    "1. Use the Proteome Data Commons (PDC) API to retreive protein relative expression data for a [CPTAC](https://proteomics.cancer.gov/programs/cptac) study.  The PDC uses values produced by the Common Data Analysis Pipeline ([CDAP](https://cptac-data-portal.georgetown.edu/cptac/documents/CDAP_ProteinReports_description_20160503.pdf)).  More information on the PDC implmentation of the CDAP can be found [here](https://pdc.esacinc.com/data-dictionary/harmonization.html).  <u>Note</u>: TMT/iTRAQ data are provided as log2ratios, where the denominator is a control channel.  In general, control channels are different between studies so comparisons *between* studies using these values are not currently reccomended in the absence of bridging data.\n",
    "2. Use the PDC API to retrieve the associated clinical metadata for all samples\n",
    "3. Format the data for analysis using pandas\n",
    "4. Cluster and visualize the data using the Seaborn clustermap package\n",
    "\n",
    "The results are intended to help identify clusters of samples (tumors) displaying similar patterns of protein expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the required imports.  Install them using pip, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Next, set up the query parameters.\n",
    "\n",
    "The first one is **pdc_submitter_id**.  This example is for the ccRCC whole proteome study.  PDC sample identifiers are available on the portal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pdc_study_id = 'PDC000127'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next one is **data type**. \n",
    "A table of data_types is available [here](https://pdc-dev.esacinc.com/data-dictionary/publicapi-documentation/#!/Paginated_Records/paginatedDataMatrix).  A description of how these values are computed can be found [here](https://cptac-data-portal.georgetown.edu/cptac/documents/CDAP_ProteinReports_description_20160503.pdf).  In brief, these values are log2 transformed ratio data, where aliquot is the numerator and the denominator is a pooled, reference sample.  Ratios are calculated following normalization in the CPTAC Common Data Analysis Pipeline (CDAP.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_type = 'log2_ratio'  # Retrieves CDAP iTRAQ or TMT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we are ready to build the query string using **pdc_study_id** and **data_type**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quant_data_query = '''\n",
    "{ \n",
    "    quantDataMatrix(\n",
    "    pdc_study_id: \"''' + pdc_study_id +'''\" data_type: \"''' + data_type + '''\" acceptDUA: true\n",
    "    )\n",
    "}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define a function to make the [GraphQL](https://graphql.org/learn/) query.  This will get called once for the gene expression data and once for the clinical data.  If you are new to GraphQL, you can also try your queries [here](https://pdc.cancer.gov/graphql)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def query_pdc(query):\n",
    "    # PDC API url\n",
    "    url = 'https://pdc.cancer.gov/graphql'\n",
    "    \n",
    "    # Send the POST graphql query\n",
    "    print('Sending query.')\n",
    "    pdc_response = requests.post(url, json={'query': query})\n",
    "    \n",
    "    # Check the results\n",
    "    if pdc_response.ok:\n",
    "        # Decode the response\n",
    "        return pdc_response.json()\n",
    "    else:\n",
    "        # Response not OK, see error\n",
    "        return pdc_response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to make the first API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "decoded = query_pdc(quant_data_query)\n",
    "\n",
    "# You may want to check this for an error, here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "matrix = decoded['data']['quantDataMatrix']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliquots are first row, gene names are first column\n",
    "ga = pd.DataFrame(matrix[1:], columns=matrix[0]).set_index('Gene/Aliquot')\n",
    "\n",
    "oldnames = list(ga.columns)\n",
    "newnames = [ x.split(':')[1] for x in oldnames ]\n",
    "\n",
    "ga.rename(columns=dict(zip(oldnames, newnames)), inplace=True)\n",
    "ga = ga.sort_index(axis=1)\n",
    "\n",
    "print(ga.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number above is the number of genes and the second is the number of samples (i.e., aliquots) in the returned data set.\n",
    "\n",
    "Since the expression values are returned as strings, we need to convert those to floats and deal with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for col in ga.keys():\n",
    "    ga[col] = pd.to_numeric(ga[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustermap module within the Seaborn package does not allow for NaN values.  So we must create a mask value that does not interfere much with the clustering and is likely to be unique.  No imputation is used.  By using a value close to 0, we are saying that these are unchanged between samples.  Better solutions should be used to deal with missing data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "mask_na = 0.000666\n",
    "ga = ga.fillna(mask_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, build the clinical data query.  This API needs only a **study_submitter_id** as input.  We will be retrieving 5 fields and using 2 in our clustergram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "metadata_query = '''\n",
    "    {\n",
    "        clinicalMetadata(pdc_study_id: \"''' + pdc_study_id + '''\" acceptDUA: true) {\n",
    "            aliquot_submitter_id\n",
    "            morphology\n",
    "            primary_diagnosis\n",
    "            tumor_grade\n",
    "            tumor_stage\n",
    "        }\n",
    "    }\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's query for the clinical metadata.  This will be used to annotate the columns (aliquots) to look for correlations between clinical attributes and samples.  That data are loaded into a dataframe after the query returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "decoded = query_pdc(metadata_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(decoded))\n",
    "clin_matrix = decoded['data']['clinicalMetadata']\n",
    "metadata = pd.DataFrame(clin_matrix, columns=clin_matrix[0]).set_index('aliquot_submitter_id')\n",
    "metadata = metadata.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set up a color mapping function for the clinical annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_colors(df, name, color) -> pd.Series:\n",
    "    s = df[name]\n",
    "    su = s.unique()\n",
    "    colors = sns.light_palette(color, len(su))\n",
    "    lut = dict(zip(su, colors))\n",
    "    return s.map(lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, call get_colors() to map the tumor_stage and primary_diagnosis attributes.  Others are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stage_col_colors = get_colors(metadata, 'tumor_stage', 'red')\n",
    "diagnosis_col_colors = get_colors(metadata, 'primary_diagnosis', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, generate the large clustermap using seaborn.clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(ga, metric='euclidean', method='complete', cmap='seismic', mask=ga == mask_na, center=0.,\n",
    "                figsize=(12.5, 50), col_colors=[stage_col_colors, diagnosis_col_colors])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also convert the log2 ratio data to a standard statistic, like z-score.\n",
    "This can help compress the range, accounting for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdf = ga.T.apply(zscore, ddof=len(ga.columns)-1)\n",
    "zdf = zdf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And examine clustering according to that transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(zdf, metric='euclidean', method='complete', cmap='seismic', mask=ga == mask_na, center=0.,\n",
    "               col_colors=[stage_col_colors, diagnosis_col_colors], figsize=(12.5, 50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, the clustermaps have been drawn.  Columns are labeled aliquot_id:aliquot_submitter_id, according to the PDC data model.  Additional work pre-processing the data, removing outliers and batch effects etc., should always be invested on any large-scale analysis.  This ends this example notebook.\n",
    "\n",
    "We hope that you found this tutorial useful.  There is also an accompanying tutorial on the PDC site, if you are finding this notebook and have not seen the video.  Please submit any questions or requests to: nci.pdc.help@esacinc.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
